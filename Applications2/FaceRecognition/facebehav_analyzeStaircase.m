function [analysis, stair] = facebehav_analyzeStaircase(stair, responses, varargin);
% Analyzes staircase data for a single run.  Fits a Weibull function to the
% data and returns the relevant parameters in an analysis struct.  The returned
% threshold is for 82% performance.
%
%  [analysis, stair] = facebehav_analyzeStaircase(stair, responses, [options]);
%
% INPUTS:
%   stair: staircase summary struct from facebehav_staircase. You can also
%   input a cell array of filenames, pointing to data files generated by
%   the staircase code. These would be found in the repository under
%   FaceRecognition/Data/. In this case, the staircase data from the
%   multiple runs will be concatenated into a single analysis.
%
%   responses: responses struct from facebehav_staircase. This can be empty
%   if a list of filenames are provided; they will be loaded from the data
%   files.
%
% Optional arguments can be passed in to effect different actions:
%
%	'doPlot'	Plots the data and the Weibull fit.  The fit gets returned, too.
%
%	'threshErr'	Calculates the stderr of the threshold by bootstrapping the data.
%				This flag must be followed by the number of iterations with
%				which to randomize the data.
%
% OUTPUTS:
%
%   analysis: structure with the following fields:
%       thresh: estimated 82% performance threshold by a Weibull fit.
%
%       slope: slope of the Weibull fit.
%
%       guess: guess rate used for the fitting (chance performance?).
%       Should be 50% for these match/nonmatch tasks
%
%       flake: flake rate (ceiling) for the fitting. Should be 0.999.
%
%       q: the probability that the chisq value of the best-fitting params
%       is as high as it is due to noise in the data.  In other words, a high
%       q value (say > .1) means that the model is a good fit.  A low q means
%       that it is unlikely that the fit error is due to chance, so it's probably
%       due to a bad model.
%
%       chisq: chi-square goodness-of-fit measure for the fitting.
%
%       df: degrees of freedom of the fitting.
%
%       x: the stimulus levels for those levels which had 6 trials or more.
%
%       y: the proporition correct by level (across all staircases) for
%       those levels which had 6 trials or more.
%
%       n: trial count for those levels which had 6 trials or more.
%
%       wx, wy: (x, y) points for the fitted Weibull function.
%
%       threshErr: std. error of the threshold estimated via bootstrapping.
%       Will only have a value if the 'threshErr' option is passed in,
%       otherwise it will be set to NaN.
%
%
%   stair: modified staircase struct, with some fields added. These include
%   trialCountByLevel, percentCorrectByLevel. For multiple filename inputs,
%   this will have all the staircases concatenated together.
%
% ras 07/14/2009, based off ras_analyzeStaircase, which was based off
% analyzeStaircase.
% dependencies: fitFunc (which calls WeibullLikelihood which calls weib)
if notDefined('stair') & notDefined('responses')
    % ask the user to select some files
    codeDir = fileparts( which(mfilename) );
    dataDir = fullfile(codeDir, 'Data');
    w = dir(fullfile(dataDir, '*-*-*.mat'));
    
    % set up a user dialog
    dlg.fieldName = 'whichFiles';
    dlg.style = 'listbox';
    dlg.list = {w.name};
    dlg.value = [];
    dlg.string = 'Select the staircase files to analyze';
    
    % get the user response
    [resp ok] = generalDialog(dlg, 'Staircase analysis');
    if ~ok, disp('User aborted'); return; end
    
    % parse the user response
    stair = resp.whichFiles;
end

% if multiple filenames are provided, load the all up, concatenate across runs,
% then re-call this function on the loaded variables:
if iscell(stair)
    dataFiles = stair;  clear stair
    for ii = 1:length(dataFiles)
        load(dataFiles{ii}, 'stim')
        if ii==1
            stair = stim.stair;
            responses = stim.responses;
        else
            %% add this run's data to the combinated data
            % an implicit assumption of this approach is that the data
            % being concatenated must have the same set of stimulus levels
            % Combining mixed staircase levels is a bit too complicated.
            
            % the history and reversal noise level fields may not be the same size for
            % concatenating -- zero pad:
			if isfield(stair, 'reversalNoiseLevel')
				n1 = size(stair.reversalNoiseLevel, 1);
				n2 = size(stim.stair.reversalNoiseLevel, 1);
				if n1 > n2
				   stim.stair.reversalNoiseLevel(n1,:) = 0;
				elseif n2 > n1
				   stair.reversalNoiseLevel(n2,:) = 0;
				end
			end
			
            n1 = size(stair.history, 1);
            n2 = size(stim.stair.history, 1);
            if n1 > n2
               stim.stair.history(n1,:) = 0;
            elseif n2 > n1
               stair.history(n2,:) = 0;
            end
            
            % the rest of the stair fields we will add as extra columns to
            % the existing stair struct:
            fields = setdiff(fieldnames(stair), {'staircasedParameter' 'levels'});
            for f = 1:length(fields)
                stair.(fields{f}) = [stair.(fields{f}) stim.stair.(fields{f})];
            end
            
            % concatenate responses -- we increment the curStair field to
            % make each staircase from each run unique
            N = stair.numStaircases(ii-1);
            responses.curStair = [responses.curStair stim.responses.curStair + N];
            fields = setdiff(fieldnames(responses), ...
                                {'task' 'staircasedParameter' 'curStair'});
            for f = 1:length(fields)
                x = fields{f};
                responses.(x) = [responses.(x) stim.responses.(x)];
            end
        end
    end
    
    % now analyze the combined data
    [analysis stair] = facebehav_analyzeStaircase(stair, responses, varargin);
    return
end

% compute # correct trials by staircase, if it's not already there
% we ignore the first N trials, where we set N here (the subject's getting
% warmed up)
nTrialsToDiscard = 10;
nTrials = length(responses.correct);
if ~isfield(stair,'numCorrect')
    for ii = 1:length(stair.trialCount)
        thisStair = find(responses.curStair==ii & [1:nTrials] > nTrialsToDiscard);
        stair.numCorrect(ii) = sum(responses.correct(thisStair));
    end
end

% bin accuracy by stimulus level
stair.numCorrectByLevel = [];  % intialize
stair.trialCountByLevel = [];  % (saved data may have its own version of this)
for ii = 1:length(stair.levels)
    rng = find(responses.level==ii & [1:nTrials] > nTrialsToDiscard);
    stair.numCorrectByLevel(ii) = sum(responses.correct(rng));
    stair.trialCountByLevel(ii) = length(responses.correct(rng));
end

stair.percentCorrectByLevel = stair.numCorrectByLevel./stair.trialCountByLevel;

%% grab relevant varibles
% For fitting a Weibull, increasing X should reflect increasing SIGNAL,
% rather than increasing noise (as is the convention I used in the
% staircase stimulus code). The signal is just 1 - the noise:
x = 1 - stair.levels(:)';
k = stair.numCorrectByLevel(:)';
n = stair.trialCountByLevel(:)';

% 07.27.99  RFD: ignore data points with <6 trials
ok = find(n>=6);
data = [x(ok); k(ok)./n(ok)];

%% initial parameters for the function-fitting
thresh = median(x);	% starting value
guess = 0.5;
flake = 0.999;
maxThresh = 100;

varargin = unNestCell(varargin);
doFixSlope = find(strcmp('fixSlope',varargin));
if ~isempty(doFixSlope)
    slope = varargin{doFixSlope+1};
    free = 1;
else
    slope = 3.5;
    free = [1 2];
end
startParams = [thresh slope guess flake maxThresh];

%% main step: run the Weibull fitting to the data
[fitParams q chisq df] = fitFunc(startParams, data, free, 'WeibullLikelihood', n(ok));

%% organize the relevant variables into the analysis struct
analysis.thresh = fitParams(1);
analysis.slope = fitParams(2);
analysis.guess = fitParams(3);
analysis.flake = fitParams(4);
analysis.q = q;
analysis.chisq = chisq;
analysis.df = df;
analysis.x = data(1,:);
analysis.y = data(2,:);
analysis.n = n(ok);

%% plot results if requested
% if any(strcmp('doPlot',varargin))
    logx = log10(data(1,:));
    logx(logx < -3) = -3;  % prevent -Inf for stimulus levels close to zero
    analysis.wx = logspace( min(logx(:)), max(logx(:)) );
    analysis.wy = weib(analysis.wx, analysis.thresh, analysis.slope, analysis.guess, analysis.flake);
    figure('Color', 'w', 'Name', [responses.task ' task']); hold on
    semilogx(analysis.wx, analysis.wy, 'k--', 'LineWidth', 2);
    plot(analysis.x, analysis.y, 'ro', 'MarkerSize', 5);
    set(gca,'FontSize',14);
    axis([min(analysis.wx),max(analysis.wx),0,1.1]);
    xlabel('Face Signal (1 - Noise)', 'FontSize', 14);
    ylabel('Accuracy', 'FontSize', 14);
% end

%% if requested, run bootstrapping to get an error bound on the threshold
%% estimate:
doThreshErr = any(strcmp('threshErr',varargin));
if doThreshErr
    y0 = data(2,:);
    n0 = n(ok);
    free = 1;
    startParams = fitParams;
    threshes = [];
    fprintf('Doing resampling');
    for ii=1:varargin{doThreshErr+1}
        for jj=1:length(y0)
            data(2,jj) = resamplePC(y0(jj),n0(jj));
        end
        fitParams = fitFunc(startParams, data, free, 'WeibullLikelihood', n0);
        if fitParams(1)<1000
            threshes = [threshes fitParams(1)];
        end
        if ~mod(ii,20)
            fprintf('.');
        end
    end
    analysis.threshErr = std(threshes);
    fprintf('\n');
else
    analysis.threshErr = NaN;
end

return
% /---------------------------------------------------------------------/ %




% /---------------------------------------------------------------------/ %
function y = resamplePC(y0, n)
% y0=proportionCorrect, n=numTrials
% this function creates an n-long vector with y 1's,
% resamples it (with replacement) and returns a new
% proportionCorrect value

nCorrect = round(y0*n);
% do the easy ones first
if nCorrect==n
    y=1;
    return;
elseif nCorrect==0
    y=0;
    return;
end

% create the data vector
z0 = [ones(1,nCorrect), zeros(1,n-nCorrect)];

% resample it, with replacement
y = 0;
for ii=1:length(z0)
    y = y+z0(ceil(rand*n));
end
y = y/n;
return
